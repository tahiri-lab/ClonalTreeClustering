{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba5345ad-48b3-4827-b8b0-75a263042739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to /home/local/USHERBROOKE/farm2103/1.mahsa.farnia/OneDrive_1_13-07-2024/newicks/Real_Dataset/output.txt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "from Bio import Phylo\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "\n",
    "def parse_newick(newick):\n",
    "    pattern = r'([^:@(),]+)@(\\d+):([\\d.]+)'\n",
    "    matches = re.findall(pattern, newick)\n",
    "    node_weights = {node: float(weight) for node, weight, _ in matches}\n",
    "    return node_weights\n",
    "\n",
    "def normalize_weights(weights_dict):\n",
    "    all_weights = list(weights_dict.values())\n",
    "    non_zero_weights = [w for w in all_weights if w != 0]\n",
    "    if not non_zero_weights:\n",
    "        return {node: 0 for node in weights_dict}\n",
    "    min_weight = min(non_zero_weights)\n",
    "    max_weight = max(non_zero_weights)\n",
    "    if min_weight == max_weight:\n",
    "        return {node: 1 if weight != 0 else 0 for node, weight in weights_dict.items()}\n",
    "    return {node: (weight - min_weight) / (max_weight - min_weight) if weight != 0 else 0\n",
    "            for node, weight in weights_dict.items()}\n",
    "\n",
    "def calculate_distances(newick):\n",
    "    tree = Phylo.read(StringIO(newick), \"newick\")\n",
    "    terminals = tree.get_terminals()\n",
    "    seq_names_full = [terminal.name for terminal in terminals if terminal.name.startswith('seq')]\n",
    "    seq_names = [name.split('@')[0] for name in seq_names_full]\n",
    "    distances = np.zeros((len(seq_names), len(seq_names)))\n",
    "    \n",
    "    for i, seq1 in enumerate(seq_names_full):\n",
    "        for j, seq2 in enumerate(seq_names_full):\n",
    "            if i != j:\n",
    "                distances[i, j] = tree.distance(seq1, seq2)\n",
    "    \n",
    "    return seq_names, distances\n",
    "\n",
    "def normalize_matrix(matrix):\n",
    "    min_val = np.min(matrix)\n",
    "    max_val = np.max(matrix)\n",
    "    if min_val == max_val:\n",
    "        return np.zeros_like(matrix)\n",
    "    return (matrix - min_val) / (max_val - min_val)\n",
    "\n",
    "def calculate_D(dist1, dist2, max_nodes):\n",
    "    if dist1.shape[0] < max_nodes:\n",
    "        dist1 = np.pad(dist1, ((0, max_nodes - dist1.shape[0]), (0, max_nodes - dist1.shape[1])))\n",
    "    if dist2.shape[0] < max_nodes:\n",
    "        dist2 = np.pad(dist2, ((0, max_nodes - dist2.shape[0]), (0, max_nodes - dist2.shape[1])))\n",
    "    \n",
    "    diff = dist1 - dist2\n",
    "    diff_squared = np.power(diff, 2)\n",
    "    sum_diff_squared = np.sum(diff_squared)\n",
    "    root_sum_squared = np.sqrt(sum_diff_squared)\n",
    "    return root_sum_squared / max_nodes\n",
    "\n",
    "def calculate_penalty(tree1, tree2):\n",
    "    common_nodes = np.sum(np.logical_and(tree1 != 0, tree2 != 0))\n",
    "    total_nodes = np.sum(np.logical_or(tree1 != 0, tree2 != 0))\n",
    "    return 1 - (common_nodes / total_nodes)\n",
    "\n",
    "# Main script\n",
    "input_path = os.path.expanduser(\"~/1.mahsa.farnia/OneDrive_1_13-07-2024/newicks/Real_Dataset/weighted_newicks.txt\")\n",
    "output_path = os.path.expanduser(\"~/1.mahsa.farnia/OneDrive_1_13-07-2024/newicks/Real_Dataset/output.txt\")\n",
    "\n",
    "with open(input_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "all_weights = {}\n",
    "all_distances = []\n",
    "all_seq_names = []\n",
    "tree_labels = []\n",
    "\n",
    "for i, line in enumerate(lines, start=1):\n",
    "    line = line.strip()\n",
    "    if not line or ':' not in line:\n",
    "        continue\n",
    "    \n",
    "    tree_label, newick = line.split(':', 1)\n",
    "    tree_labels.append(f\"Tree {i}\")\n",
    "    newick = newick.strip()\n",
    "    \n",
    "    weights = parse_newick(newick)\n",
    "    for node, weight in weights.items():\n",
    "        if node not in all_weights:\n",
    "            all_weights[node] = [0] * (i - 1)\n",
    "        all_weights[node].append(weight)\n",
    "    \n",
    "    for node in all_weights:\n",
    "        if len(all_weights[node]) < i:\n",
    "            all_weights[node].extend([0] * (i - len(all_weights[node])))\n",
    "    \n",
    "    try:\n",
    "        seq_names, distances = calculate_distances(newick)\n",
    "        normalized_distances = normalize_matrix(distances)  # Normalize the distances\n",
    "        all_distances.append(normalized_distances)  # Store the normalized distances\n",
    "        all_seq_names.append(seq_names)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error processing tree {tree_label}: {e}\")\n",
    "        continue\n",
    "\n",
    "all_nodes = sorted(all_weights.keys())\n",
    "original_weights_matrix = np.array([all_weights[node] for node in all_nodes])\n",
    "\n",
    "nodes_per_tree = np.count_nonzero(original_weights_matrix, axis=0)\n",
    "\n",
    "normalized_weights_matrix = np.zeros_like(original_weights_matrix)\n",
    "for i, node in enumerate(all_nodes):\n",
    "    normalized_weights = normalize_weights(dict(enumerate(all_weights[node])))\n",
    "    normalized_weights_matrix[i] = [normalized_weights[j] for j in range(len(tree_labels))]\n",
    "\n",
    "num_trees = len(tree_labels)\n",
    "diff_columns = []\n",
    "diff_labels = []\n",
    "normalized_diff_sums = []\n",
    "\n",
    "for i in range(num_trees):\n",
    "    for j in range(i+1, num_trees):\n",
    "        diff = np.abs(normalized_weights_matrix[:, i] - normalized_weights_matrix[:, j])\n",
    "        diff_columns.append(diff)\n",
    "        diff_labels.append(f\"Diff {tree_labels[i]}-{tree_labels[j]}\")\n",
    "        \n",
    "        max_nodes = max(nodes_per_tree[i], nodes_per_tree[j])\n",
    "        normalized_sum = np.sum(diff) / max_nodes\n",
    "        normalized_diff_sums.append(normalized_sum)\n",
    "\n",
    "extended_normalized_matrix = np.hstack((normalized_weights_matrix, np.column_stack(diff_columns)))\n",
    "\n",
    "column_sums = np.sum(extended_normalized_matrix, axis=0)\n",
    "\n",
    "D_values = {}\n",
    "P_values = {}\n",
    "W_values = {}\n",
    "GBLD_values = {}\n",
    "\n",
    "for i in range(num_trees):\n",
    "    for j in range(i+1, num_trees):\n",
    "        max_nodes = max(nodes_per_tree[i], nodes_per_tree[j])\n",
    "        D = calculate_D(all_distances[i], all_distances[j], max_nodes)\n",
    "        D_values[(tree_labels[i], tree_labels[j])] = D\n",
    "        \n",
    "        P = calculate_penalty(original_weights_matrix[:, i], original_weights_matrix[:, j])\n",
    "        P_values[(tree_labels[i], tree_labels[j])] = P\n",
    "        \n",
    "        W = normalized_diff_sums[len(W_values)]\n",
    "        W_values[(tree_labels[i], tree_labels[j])] = W\n",
    "        \n",
    "        GBLD = P + W + D\n",
    "        GBLD_values[(tree_labels[i], tree_labels[j])] = GBLD\n",
    "\n",
    "# Save results\n",
    "with open(output_path, 'w') as f:\n",
    "    f.write(\"Original Weights:\\n\")\n",
    "    f.write(\"Node,\" + \",\".join(tree_labels) + \"\\n\")\n",
    "    for i, node in enumerate(all_nodes):\n",
    "        f.write(f\"{node},\" + \",\".join(f\"{val:.4f}\".rjust(10) for val in original_weights_matrix[i]) + \"\\n\")\n",
    "    \n",
    "    f.write(\"\\nNormalized Weights with Differences:\\n\")\n",
    "    f.write(\"Node,\" + \",\".join(tree_labels) + \",\" + \",\".join(diff_labels) + \"\\n\")\n",
    "    for i, node in enumerate(all_nodes):\n",
    "        f.write(f\"{node},\" + \",\".join(f\"{val:.4f}\".rjust(10) for val in extended_normalized_matrix[i]) + \"\\n\")\n",
    "    \n",
    "    f.write(\"Sum,\" + \",\".join(f\"{val:.4f}\".rjust(10) for val in column_sums) + \"\\n\")\n",
    "    \n",
    "    normalized_sums_row = [\"-\"] * num_trees + [f\"{val:.4f}\".rjust(10) for val in normalized_diff_sums]\n",
    "    f.write(\"Normalized Sum,\" + \",\".join(normalized_sums_row) + \"\\n\")\n",
    "    \n",
    "    f.write(\"Nodes,\" + \",\".join(f\"{val}\".rjust(10) for val in nodes_per_tree) + \"\\n\")\n",
    "\n",
    "    f.write(\"\\nD_(T1,T2) Values:\\n\")\n",
    "    for (tree1, tree2), D in D_values.items():\n",
    "        f.write(f\"D_({tree1},{tree2}) = {D:.4f}\\n\")\n",
    "\n",
    "    f.write(\"\\nP_(T1,T2) Values (Penalty):\\n\")\n",
    "    for (tree1, tree2), P in P_values.items():\n",
    "        f.write(f\"P_({tree1},{tree2}) = {P:.4f}\\n\")\n",
    "\n",
    "    f.write(\"\\nW_(T1,T2) Values:\\n\")\n",
    "    for (tree1, tree2), W in W_values.items():\n",
    "        f.write(f\"W_({tree1},{tree2}) = {W:.4f}\\n\")\n",
    "\n",
    "    f.write(\"\\nGBLD_(T1,T2) Values:\\n\")\n",
    "    for (tree1, tree2), GBLD in GBLD_values.items():\n",
    "        f.write(f\"GBLD_({tree1},{tree2}) = {GBLD:.4f}\\n\")\n",
    "\n",
    "    f.write(\"\\nNormalized Distances:\\n\")\n",
    "    for i, (distances, seq_names) in enumerate(zip(all_distances, all_seq_names)):\n",
    "        tree_label = lines[i].split(':', 1)[0]\n",
    "        f.write(f\"{tree_label}: ,{',      '.join(seq_names)}\\n\")\n",
    "        for j, row in enumerate(distances):\n",
    "            f.write(f\"{seq_names[j]},\" + \",\".join(f\"{val:.4f}\".rjust(10) for val in row) + \"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"Results saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986d8d69-f737-4170-adb4-0a04024ecd84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
